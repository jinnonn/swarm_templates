# my global config
global:
  scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.
  evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.
  # scrape_timeout is set to the global default (10s).

# Alertmanager configuration
alerting:
  alertmanagers:
    - static_configs:
        - targets:
            - localhost:9093

# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
rule_files:
  - rules.yml

# A scrape configuration containing exactly one endpoint to scrape:
# Here it's Prometheus itself.
scrape_configs:
  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
  - job_name: "prometheus"

    # metrics_path defaults to '/metrics'
    # scheme defaults to 'http'.

    static_configs:
      - targets: ["localhost:9090"]

  - job_name: "node_exporter"

    static_configs:

      - targets: ['localhost:9100']
        labels:
          env: 'prometheus'

      - targets: ['192.200.0.220:9100']
        labels:
          env: 'manager'

      - targets: ['192.200.0.221:9100']
        labels:
          env: 'worker'
          location: 'samara'

    relabel_configs:
    - source_labels: [__address__, env]
      target_label: full_info

  - job_name: "docker_swarm_nodes"

    dockerswarm_sd_configs:
      - host: http://192.200.0.220:2375
        role: nodes

    relabel_configs:
      # Fetch metrics on port 9323.
      - source_labels: [__meta_dockerswarm_node_address]
        target_label: __address__
        replacement: $1:9323
      - source_labels: [__meta_dockerswarm_node_address]
        target_label: test_address
        replacement: $1:9323
      # Set hostname as instance label
      - source_labels: [__meta_dockerswarm_node_hostname]
        target_label: instance

  - job_name: "docker_swarm_tasks"

    dockerswarm_sd_configs:
      - host: http://192.200.0.220:2375
        role: tasks
    
    # relabel_configs:
    #   # # Это правило нужно, чтобы эндпоинты формировались из меток prometheus-job и prometheus-port
    #   - source_labels: [__meta_dockerswarm_node_address, __meta_dockerswarm_service_label_prometheus_port]
    #     separator: ':'
    #     target_label: __address__
    #   - source_labels: [__meta_dockerswarm_task_desired_state]
    #     regex: running
    #     action: keep
    #   # Only keep containers that have a `prometheus-job` label.
    #   - source_labels: [__meta_dockerswarm_service_label_prometheus_job]
    #     regex: .+
    #     action: keep
    #   # Use the prometheus-job Swarm label as Prometheus job label.
    #   - source_labels: [__meta_dockerswarm_service_label_prometheus_job]
    #     target_label: job

    relabel_configs:
      - source_labels: [__meta_dockerswarm_node_address]
        target_label: __address__
        replacement: $1:9500
      - source_labels: [__meta_dockerswarm_task_desired_state]
        regex: running
        action: keep
      # Only keep containers that have a `prometheus-job` label.
      # - source_labels: [__meta_dockerswarm_service_label_prometheus_job]
      #   regex: .+
      #   action: keep
      # Use the prometheus-job Swarm label as Prometheus job label.
      # - source_labels: [__meta_dockerswarm_service_label_prometheus_job]
      #   target_label: job    
